<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Statistical Learning | 02-statistical-learning.knit</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Statistical Learning | 02-statistical-learning.knit" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Statistical Learning | 02-statistical-learning.knit" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  


<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">ISLR Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path=""><a href="#statistical-learning"><i class="fa fa-check"></i><b>1</b> Statistical Learning</a>
<ul>
<li class="chapter" data-level="1.1" data-path=""><a href="#what-is-statistical-learning"><i class="fa fa-check"></i><b>1.1</b> 2.1 What Is Statistical Learning?</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path=""><a href="#why-estimate-f"><i class="fa fa-check"></i><b>1.1.1</b> 2.1.1 Why Estimate f?</a></li>
<li class="chapter" data-level="1.1.2" data-path=""><a href="#how-do-we-estimate-f"><i class="fa fa-check"></i><b>1.1.2</b> 2.1.2 How Do We Estimate <span class="math inline">\(f\)</span>?</a></li>
<li class="chapter" data-level="1.1.3" data-path=""><a href="#the-trade-off-between-prediction-accuracy-and-model-interpretability"><i class="fa fa-check"></i><b>1.1.3</b> 2.1.3 The Trade-Off Between Prediction Accuracy and Model Interpretability</a></li>
<li class="chapter" data-level="1.1.4" data-path=""><a href="#supervised-versus-unsupervised-learning"><i class="fa fa-check"></i><b>1.1.4</b> 2.1.4 Supervised Versus Unsupervised Learning</a></li>
<li class="chapter" data-level="1.1.5" data-path=""><a href="#regression-versus-classification-problems"><i class="fa fa-check"></i><b>1.1.5</b> 2.1.5 Regression Versus Classification Problems</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path=""><a href="#assessing-model-accuracy"><i class="fa fa-check"></i><b>1.2</b> 2.2 Assessing Model Accuracy</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path=""><a href="#measuring-the-quality-of-fit"><i class="fa fa-check"></i><b>1.2.1</b> 2.2.1 Measuring the Quality of Fit</a></li>
<li class="chapter" data-level="1.2.2" data-path=""><a href="#the-bias-variance-trade-off"><i class="fa fa-check"></i><b>1.2.2</b> 2.2.2 The Bias-Variance Trade-Off</a></li>
<li class="chapter" data-level="1.2.3" data-path=""><a href="#the-classification-setting"><i class="fa fa-check"></i><b>1.2.3</b> 2.2.3 The Classification Setting</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path=""><a href="#lab-introduction-to-r"><i class="fa fa-check"></i><b>1.3</b> 2.3 Lab: Introduction to R</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path=""><a href="#basic-commands"><i class="fa fa-check"></i><b>1.3.1</b> 2.3.1 Basic Commands</a></li>
<li class="chapter" data-level="1.3.2" data-path=""><a href="#graphics"><i class="fa fa-check"></i><b>1.3.2</b> 2.3.2 Graphics</a></li>
<li class="chapter" data-level="1.3.3" data-path=""><a href="#indexing-data"><i class="fa fa-check"></i><b>1.3.3</b> 2.3.3 Indexing Data</a></li>
<li class="chapter" data-level="1.3.4" data-path=""><a href="#loading-data"><i class="fa fa-check"></i><b>1.3.4</b> 2.3.4 Loading Data</a></li>
<li class="chapter" data-level="1.3.5" data-path=""><a href="#additional-graphical-and-numerical-summaries"><i class="fa fa-check"></i><b>1.3.5</b> 2.3.5 Additional Graphical and Numerical Summaries</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path=""><a href="#exercises"><i class="fa fa-check"></i><b>1.4</b> 2.4 Exercises</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path=""><a href="#conceptual"><i class="fa fa-check"></i><b>1.4.1</b> Conceptual</a></li>
<li class="chapter" data-level="1.4.2" data-path=""><a href="#applied"><i class="fa fa-check"></i><b>1.4.2</b> Applied</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:title:end-->
<!--bookdown:title:start-->
<div id="statistical-learning" class="section level1" number="1">
<h1><span class="header-section-number">Chapter 1</span> Statistical Learning</h1>
<div id="what-is-statistical-learning" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> 2.1 What Is Statistical Learning?</h2>
<p>Motivating example:</p>
<blockquote>
<p>Suppose that we are statistical consultants hired by a client to provide advice on how to improve sales of a particular product. … our goal is to develop an accurate model that can be used to predict sales on the basis of the three media budgets.</p>
</blockquote>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(Advertising)</span></code></pre></div>
<pre><code>## Rows: 200
## Columns: 4
## $ TV        &lt;dbl&gt; 230.1, 44.5, 17.2, 151.5, 180.8, 8.7, 57.5, 120.2, 8.6, 199.8, 66.1, 214.7, 23.8, 97.5, 204.1, 195.4, 67.8, 281.4, 69.2, 147…
## $ radio     &lt;dbl&gt; 37.8, 39.3, 45.9, 41.3, 10.8, 48.9, 32.8, 19.6, 2.1, 2.6, 5.8, 24.0, 35.1, 7.6, 32.9, 47.7, 36.6, 39.6, 20.5, 23.9, 27.7, 5.…
## $ newspaper &lt;dbl&gt; 69.2, 45.1, 69.3, 58.5, 58.4, 75.0, 23.5, 11.6, 1.0, 21.2, 24.2, 4.0, 65.9, 7.2, 46.0, 52.9, 114.0, 55.8, 18.3, 19.1, 53.4, …
## $ sales     &lt;dbl&gt; 22.1, 10.4, 9.3, 18.5, 12.9, 7.2, 11.8, 13.2, 4.8, 10.6, 8.6, 17.4, 9.2, 9.7, 19.0, 22.4, 12.5, 24.4, 11.3, 14.6, 18.0, 12.5…</code></pre>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>Advertising <span class="sc">%&gt;%</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> TV, <span class="at">y =</span> sales)) <span class="sc">+</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.25</span>, <span class="at">shape =</span> <span class="dv">1</span>) <span class="sc">+</span> </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_smooth</span>(<span class="at">formula =</span> y<span class="sc">~</span>x, <span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="pdf_document_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>Advertising <span class="sc">%&gt;%</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> radio, <span class="at">y =</span> sales)) <span class="sc">+</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.25</span>, <span class="at">shape =</span> <span class="dv">1</span>) <span class="sc">+</span> </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_smooth</span>(<span class="at">formula =</span> y<span class="sc">~</span>x, <span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="pdf_document_files/figure-html/unnamed-chunk-3-2.png" width="672" /></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>Advertising <span class="sc">%&gt;%</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> newspaper, <span class="at">y =</span> sales)) <span class="sc">+</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.25</span>, <span class="at">shape =</span> <span class="dv">1</span>) <span class="sc">+</span> </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_smooth</span>(<span class="at">formula =</span> y<span class="sc">~</span>x, <span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="pdf_document_files/figure-html/unnamed-chunk-3-3.png" width="672" /></p>
<p><strong>Input Variables</strong>: These are the variables we know and can use to build our model. Also known as <em>predictors</em>, <em>independent variables</em>, or <em>features</em>. Denoted using the symbol <span class="math inline">\(X_n\)</span>.</p>
<p><strong>Output Variable</strong>: This is the variable we are trying to predict with the model. Also known as a <em>response</em>, or <em>dependent variable</em>. Typically denoted as <span class="math inline">\(Y\)</span>.</p>
<p>More generally: <span class="math inline">\(Y = f(X) + \epsilon\)</span></p>
<p>Where <span class="math inline">\(Y\)</span> is the quantitative response and <span class="math inline">\(f\)</span> is a function of <span class="math inline">\(X_1, ..., X_p\)</span> (of <span class="math inline">\(p\)</span> different predictors) and <span class="math inline">\(\epsilon\)</span> is some random <strong>error term</strong>.</p>
<p>Assumptions:</p>
<ul>
<li><span class="math inline">\(f\)</span> is <strong>systematic</strong> in its relationship to <span class="math inline">\(Y\)</span></li>
<li><span class="math inline">\(\epsilon\)</span> is independent of <span class="math inline">\(X\)</span></li>
<li><span class="math inline">\(\epsilon\)</span> has mean zero</li>
</ul>
<p>Another example: Income and education may appear related, but the exact relationship is unknown. Note that some of the observations are above the linear interpolated line, while some are below it. The difference is <span class="math inline">\(\epsilon\)</span></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>Income1 <span class="sc">%&gt;%</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> Education, <span class="at">y =</span> Income)) <span class="sc">+</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span> </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>        <span class="fu">geom_smooth</span>(<span class="at">formula =</span> y<span class="sc">~</span>x, <span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>() </span></code></pre></div>
<p><img src="pdf_document_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<div id="why-estimate-f" class="section level3" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> 2.1.1 Why Estimate f?</h3>
<p>There are two main reasons to estimate <span class="math inline">\(f\)</span>:</p>
<ul>
<li><p>Prediction</p></li>
<li><p>Inference</p></li>
</ul>
<div id="prediction" class="section level4" number="1.1.1.1">
<h4><span class="header-section-number">1.1.1.1</span> Prediction</h4>
<p>Consider: <span class="math inline">\(\hat{Y} = \hat{f}(X)\)</span></p>
<p>If <span class="math inline">\(X\)</span> is known, we can predict <span class="math inline">\(\hat{Y}\)</span> by this equation. Don’t be too concerned with the exact functional form of <span class="math inline">\(\hat{f}\)</span>, as long as it yields accurate predictions of <span class="math inline">\(Y\)</span>.</p>
<p>The accuracy of <span class="math inline">\(\hat{Y}\)</span> depends on two quantities:</p>
<ul>
<li><p><strong>Reducible error</strong>: This is error that comes with the model. We can potentially address this error by improving the accuracy of the model.</p></li>
<li><p><strong>Irreducible error</strong>: This is error introduced to the model, because <span class="math inline">\(\epsilon\)</span>, by definition, cannot be explained by <span class="math inline">\(X\)</span></p></li>
</ul>
<p><strong>Why is irreducible error larger than zero?</strong> Consider the estimate <span class="math inline">\(\hat{f}\)</span> and a prediction <span class="math inline">\(\hat{Y} = \hat{f}(X)\)</span>. Let <span class="math inline">\(\hat{f}\)</span> and <span class="math inline">\(X\)</span> be fixed. Then:</p>
<p><span class="math display">\[
E(Y - Y^2) = E[f(X) + \epsilon - \hat{f}(X)]^2
\]</span>
<span class="math display">\[
= [f(X) - \hat{f}(X)]^2 + Var(\epsilon)
\]</span></p>
<p>Where <span class="math inline">\(E(Y - Y^2)\)</span> is the <strong>expected value</strong> of the squared difference between the predicted and actual value of <span class="math inline">\(Y\)</span>, and <span class="math inline">\(Var(X)\)</span> is the <strong>variance</strong> associated with the error term <span class="math inline">\(\epsilon\)</span>.</p>
</div>
<div id="inference" class="section level4" number="1.1.1.2">
<h4><span class="header-section-number">1.1.1.2</span> Inference:</h4>
<p>When used for inference, the aim is not to use estimate <span class="math inline">\(f\)</span> for predictions, but rather to understand how some response <span class="math inline">\(Y\)</span> is affected by the changes in <span class="math inline">\(X_1, ..., X_p\)</span>.</p>
<ul>
<li><strong>Which predictors are associated with the response?</strong>: Identifying the <strong>important</strong> predictors is the aim here.<br />
</li>
<li><strong>What is the relationship between the response and each predictor?</strong>: This can be positive, negative, or depend on the values of other predictors, depending on how complicated the model is.<br />
</li>
<li><strong>Can the relationship between</strong> <span class="math inline">\(Y\)</span> and each predictor be summarized using a linear equation?</li>
</ul>
<p>Examples:</p>
<p><strong>Prediction</strong>: A Company using a model to identify target customers for a direct-marketing campaign. The company is not interested in the model, they just want a function form that will help them.</p>
<p><strong>Inference</strong>: Modeling customer purchases of specific brands of products. The model is aimed toward explaining which components of the model affect probability of a purchase.</p>
<p>Functional form: In many cases, a <strong>linear model</strong> allows for a relatively interpretable form, but may not be as flexible or accurate as other models.</p>
</div>
</div>
<div id="how-do-we-estimate-f" class="section level3" number="1.1.2">
<h3><span class="header-section-number">1.1.2</span> 2.1.2 How Do We Estimate <span class="math inline">\(f\)</span>?</h3>
<p>There are many different approaches to estimating <span class="math inline">\(f\)</span>, which all share certain characteristics and terms.</p>
<ul>
<li>Training Data: This is the data used to train or teach our model how to estimate <span class="math inline">\(\hat{f}\)</span>. In general, most estimation methods can be characterized as either <strong>parametric</strong> or <strong>non-parametric</strong>.</li>
</ul>
<div id="parametric-methods" class="section level4" number="1.1.2.1">
<h4><span class="header-section-number">1.1.2.1</span> <strong>Parametric Methods</strong>:</h4>
<p>Involves a two-step model-base approach:</p>
<ol style="list-style-type: decimal">
<li>Assume functional form.</li>
</ol>
<p>Example: <span class="math inline">\(f(X) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_p X_p\)</span> (This is a <em>linear</em> model)</p>
<ol start="2" style="list-style-type: decimal">
<li>After model selection, identify the procedure to estimate the parameters of the model. For linear models, this would be the method of estimating <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, … etc such that:</li>
</ol>
<p><span class="math display">\[
Y \approx \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_p X_p
\]</span></p>
<p>The most common approach with linear models is the <strong>(Ordinary) least squares</strong> method. The parametric method reduces estimation to determining a set of <strong>parameters</strong> that create the best fit for an assumed functional form.</p>
<p>Pros:</p>
<ul>
<li>Assuming the form makes estimation simpler!</li>
</ul>
<p>Potential Cons:</p>
<ul>
<li><p>We don’t know the true <span class="math inline">\(f\)</span>, and we could be way off!</p></li>
<li><p>We can choose more flexible models to address this, but…</p></li>
<li><p>More flexible models lead to more parameters to estimate, and potentially <strong>overfitting</strong>.</p></li>
</ul>
</div>
<div id="non-parametric-methods" class="section level4" number="1.1.2.2">
<h4><span class="header-section-number">1.1.2.2</span> <strong>Non-parametric Methods</strong></h4>
<p>Pro: Do not make assumptions about functional form.</p>
<p>Con: Require a large number of observations to obtain an estimate of <span class="math inline">\(f\)</span></p>
</div>
</div>
<div id="the-trade-off-between-prediction-accuracy-and-model-interpretability" class="section level3" number="1.1.3">
<h3><span class="header-section-number">1.1.3</span> 2.1.3 The Trade-Off Between Prediction Accuracy and Model Interpretability</h3>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">10</span>,</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">type =</span> <span class="st">&#39;n&#39;</span>,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">xaxt =</span> <span class="st">&#39;none&#39;</span>,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">yaxt =</span> <span class="st">&#39;none&#39;</span>,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;Flexibility&quot;</span>, </span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab =</span> <span class="st">&quot;Interpretability&quot;</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">1</span>, <span class="at">at =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="fl">8.75</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Low&quot;</span>, <span class="st">&quot;High&quot;</span>))</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">2</span>, <span class="at">at =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="fl">8.75</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Low&quot;</span>, <span class="st">&quot;High&quot;</span>))</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x=</span><span class="dv">1</span>, <span class="at">y=</span><span class="fl">9.5</span>, <span class="st">&quot;Subset Selection&quot;</span>, <span class="at">font=</span><span class="dv">1</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x=</span><span class="dv">1</span>, <span class="at">y=</span><span class="fl">8.5</span>, <span class="st">&quot;Lasso&quot;</span>, <span class="at">font=</span><span class="dv">1</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x=</span><span class="fl">3.25</span>, <span class="at">y=</span><span class="fl">6.75</span>, <span class="st">&quot;Least Squares&quot;</span>, <span class="at">font=</span><span class="dv">1</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x=</span><span class="fl">4.75</span>, <span class="at">y=</span><span class="dv">5</span>, <span class="st">&quot;Generalized Additive Models&quot;</span>, <span class="at">font=</span><span class="dv">1</span>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x=</span><span class="fl">4.75</span>, <span class="at">y=</span><span class="fl">4.5</span>, <span class="st">&quot;Trees&quot;</span>, <span class="at">font=</span><span class="dv">1</span>)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x=</span><span class="fl">8.75</span>, <span class="at">y=</span><span class="dv">3</span>, <span class="st">&quot;Bagging, Boosting&quot;</span>, <span class="at">font=</span><span class="dv">1</span>)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x=</span><span class="fl">7.5</span>, <span class="at">y=</span><span class="fl">1.25</span>, <span class="st">&quot;Support Vector Machines&quot;</span>, <span class="at">font=</span><span class="dv">1</span>)</span></code></pre></div>
<p><img src="pdf_document_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<table>
<thead>
<tr class="header">
<th>Method</th>
<th>Pro</th>
<th>Con</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Linear Regression</td>
<td>Easy to interpret</td>
<td>Relatively inflexible</td>
</tr>
<tr class="even">
<td>Thin Plate Splines</td>
<td>Very flexible</td>
<td>Difficult to understand</td>
</tr>
<tr class="odd">
<td><strong>lasso</strong></td>
<td>More interpretable</td>
<td>less flexible</td>
</tr>
<tr class="even">
<td>GAMs</td>
<td>more flexible</td>
<td>less interpretable</td>
</tr>
</tbody>
</table>
</div>
<div id="supervised-versus-unsupervised-learning" class="section level3" number="1.1.4">
<h3><span class="header-section-number">1.1.4</span> 2.1.4 Supervised Versus Unsupervised Learning</h3>
<blockquote>
<p>Most statistical learning problems fall into one of two categories: supervised or unsupervised.</p>
</blockquote>
<p><em>Supervised Learning</em>: For each observation of the predictor measurements <span class="math inline">\(X_i\)</span>, there is an associated response measurement <span class="math inline">\(Y_i\)</span>. These are models where we want to predict <strong>outcomes</strong>.</p>
<p><em>Unsupervised Learning</em>: For each observation of the predictor measurements <span class="math inline">\(X_i\)</span>, there is <strong>No</strong> associated response measurement <span class="math inline">\(Y_i\)</span>(!) - In this scenario, it is not possible to fit a linear regression, since there is no associated <span class="math inline">\(Y_i\)</span>.</p>
<div id="cluster-analysis" class="section level4" number="1.1.4.1">
<h4><span class="header-section-number">1.1.4.1</span> Cluster Analysis</h4>
<p>One way to understand unsupervised models is through <strong>cluster analysis</strong>. The goal of this type of analysis is to determine whether <span class="math inline">\(x_i, ..., x_n\)</span> fall into relatively distinct groups.</p>
<p>Note:</p>
<ul>
<li><p>Clustering methods are imprecise – They cannot assign all points to their correct group.</p></li>
<li><p>If there are <span class="math inline">\(p\)</span> variables, then <span class="math inline">\(p(p- 1) /2)\)</span> scatterplots can be made, this is why automated clustering methods are important.</p></li>
<li><p>There are instances where it is not clear whether a problem is <em>supervised</em> or <em>unsupervised</em> – Some <span class="math inline">\(Y\)</span>’s exist, but not all. These are referred to as <em>semi-supervised learning problems</em>.</p></li>
</ul>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>iris_cluster <span class="ot">&lt;-</span> iris[, <span class="sc">-</span><span class="dv">5</span>]</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>cls <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(<span class="at">x =</span> iris_cluster, <span class="at">centers =</span> <span class="dv">3</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>iris_cluster<span class="sc">$</span>cluster <span class="ot">&lt;-</span> <span class="fu">as.character</span>(cls<span class="sc">$</span>cluster)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> iris_cluster, </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>             <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> Sepal.Length, </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">y =</span> Petal.Length, </span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">colour =</span> cluster))</span></code></pre></div>
<p><img src="pdf_document_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># borrowed from: https://rpubs.com/aephidayatuloh/clustervisual</span></span></code></pre></div>
</div>
</div>
<div id="regression-versus-classification-problems" class="section level3" number="1.1.5">
<h3><span class="header-section-number">1.1.5</span> 2.1.5 Regression Versus Classification Problems</h3>
<ul>
<li>Problems with a <em>quantitative response value</em> (numeric) are referred to as <em>regression problems</em>.</li>
<li>Problems with a <em>qualitative response</em> – a value in one of <span class="math inline">\(K\)</span> different classes, are referred to as <em>classification problems</em>.</li>
<li>Qualitative responses are also referred to as <em>categorical values</em>.</li>
</ul>
</div>
</div>
<div id="assessing-model-accuracy" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> 2.2 Assessing Model Accuracy</h2>
<blockquote>
<p>There is no free lunch in statistics: no one method dominates all others over all possible data sets. On a particular data set, one specific method may work best, but some other method may work better on a similar but different data set.</p>
</blockquote>
<div id="measuring-the-quality-of-fit" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> 2.2.1 Measuring the Quality of Fit</h3>
<p>When using regressions, quality of fit is most commonly assessed by <strong>mean squared error</strong> (MSE):</p>
<p><span class="math display">\[
MSE = \frac{1}{n}\sum_{i=1}^n(y_i - \hat{f}(x_i))^2
\]</span>
<span class="math inline">\(\hat{f}(x_i))^2\)</span> is the prediction.</p>
<p>The <em>training</em> MSE will be small if the predicted responses are close to the true responses, and larger if the estimates of the predictions are farther from the true responses.</p>
<p>Examples:</p>
<ul>
<li><p>If we are interested in stock prices based on the previous 6 months, we really only care about how well the algorithm predicts <em>tomorrow’s price</em>.</p></li>
<li><p>If we train a model on diabetes patient’s clinical measurements, we are only concerned with how well the model predicts <em>future</em> diabetes patients.</p></li>
</ul>
<p>Mechanically: If we fit our method on training observations <span class="math inline">\({(x_1, y_1), (x_2, y_2), …, (x_n, y_n)}\)</span>, we use those observations to fit <span class="math inline">\(\hat{f}(x_1), \hat{f}(x_2), …, \hat{f}(x_n)\)</span>.</p>
<p>The aim here is to compute an <span class="math inline">\(\hat{f}(x_0)\)</span> which is closest to the real <em>unseen</em> <span class="math inline">\(y_0\)</span> observation, the test data.</p>
<div id="how-do-we-choose-our-model" class="section level4" number="1.2.1.1">
<h4><span class="header-section-number">1.2.1.1</span> How do we choose our model?</h4>
<p>If we have test data available (not used for training/estimating <span class="math inline">\(\hat{f}\)</span>), we can simply choose the method which minimizes <span class="math inline">\(MSE\)</span> on that test data. If we do not have testing data, we can choose the model which minimizes <span class="math inline">\(MSE\)</span> for our training data, but <strong><em>there is no guarantee that a method with the smallest training</em></strong> <span class="math inline">\(MSE\)</span> <strong><em>will result in the smallest test</em></strong> <span class="math inline">\(MSE\)</span><strong><em>.</em></strong></p>
<p>Note: As model flexibility increases, the training <span class="math inline">\(MSE\)</span> will decrease, but this does not imply that the <em>test</em> <span class="math inline">\(MSE\)</span> will similarly decrease. When a method yields a small training <span class="math inline">\(MSE\)</span> and a large test <span class="math inline">\(MSE\)</span>, we are <em>overfitting</em> our data.</p>
</div>
</div>
<div id="the-bias-variance-trade-off" class="section level3" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> 2.2.2 The Bias-Variance Trade-Off</h3>
<p>It is possible to prove that the expected test MSE can be decomposed into the sum of three quantities: the v<em>ariance</em> of <span class="math inline">\(\hat{f}(x_0)\)</span>, the squared <em>bias</em> of <span class="math inline">\(\hat{f}(x_0)\)</span>, and the variance of the error terms <span class="math inline">\(\epsilon\)</span>.</p>
<p><span class="math display">\[
E(y_0 - \hat{f}(x_0))^2 = Var(\hat{f}(x_0)) + [Bias(\hat{f}(x_0))]^2 + Var(\epsilon)
\]</span></p>
<p>To achieve a low expected test error, it is necessary to select a method that results in <em>low variance</em> and <em>low bias</em>. It’s also important to understand that the MSE will never be lower than the <span class="math inline">\(Var(\epsilon)\)</span>, the irreducible error.</p>
<p><strong>Variance</strong> refers to the amount <span class="math inline">\(\hat{f}\)</span> would change if we used different testing data. Generally, more flexible models have higher variance.</p>
<p><strong>Bias</strong> is the error introduced by using a simple model to approximate potentially complex functions. More flexible models generally have less bias.</p>
<p>The Bias-Variance trade-off is the challenge of identifying a model which has both low variance <strong>and</strong> low bias.</p>
</div>
<div id="the-classification-setting" class="section level3" number="1.2.3">
<h3><span class="header-section-number">1.2.3</span> 2.2.3 The Classification Setting</h3>
<p>In the classification context, many of the concepts above still apply, with minor differences because the <span class="math inline">\(y_0\)</span> is no longer a number value, but instead a qualitative value. The most common approach for gauging the accuracy of a qualitative <span class="math inline">\(\hat{f}\)</span> is the training <em>error rate:</em></p>
<p><span class="math display">\[
\frac 1 n \sum_{i=1}^n I(y_i \neq \hat{y_i})
\]</span></p>
<p>Where <span class="math inline">\(\hat{y_i}\)</span> is the predicted value for the <span class="math inline">\(i\)</span>th observation using the function <span class="math inline">\(\hat{f}\)</span>,</p>
<p><span class="math inline">\(I(y_i \neq \hat{y_i})\)</span> is an <em>indicator variable</em>, equal to 1 if <span class="math inline">\(y_i \neq \hat{y_i}\)</span> and zero if not. This computes the fraction of incorrect classifications.</p>
<p>As with regression methods, the our aim should be to reduce the test error rate.</p>
<div id="the-bayes-classifier" class="section level4" number="1.2.3.1">
<h4><span class="header-section-number">1.2.3.1</span> The Bayes Classifier</h4>
<p>There is a special case in which it can be shown that the test error rate is minized by <em>assigning each observation to it’s most likely class, based on it’s predictor values</em>.</p>
<p>This case is called the <strong>Bayes Classifier</strong></p>
<p><span class="math display">\[
Pr(Y = j | X = x_0)
\]</span><br />
This is the <em>conditional probability</em> that assigns a probability that <span class="math inline">\(Y = j\)</span>, given the observed value <span class="math inline">\(x_0\)</span>. In two class problems, this amounts to an assignment between two classes, <em>class one</em> if <span class="math inline">\(Pr(Y = 1 | X = x_0) &gt; 0.5\)</span>, and class two otherwise. A scenario in which the decision boundary is set to exactly 50% is called a <em>Bayes Decision Boundary</em>.</p>
<p>The Bayes classifier always yields the lowest possible test error rate, since it will assign classification based on the highest probability outcome. The <em>Bayes error rate</em> is defined as:</p>
<p><span class="math display">\[
1 - \mathrm{E} \lgroup \max_{j} \mathrm{ Pr}(Y=j|X)
\]</span>
This error rate can also be described as the ratio of classifications that end up on the “wrong” side of the decision boundary.</p>
</div>
<div id="k-nearest-neighbors" class="section level4" number="1.2.3.2">
<h4><span class="header-section-number">1.2.3.2</span> K-Nearest Neighbors</h4>
<p>For real data, we do not know the conditional distribution of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span>, so computing the Bayes classifier is impossible. One method is to estimate the distributionwith the <em>highest estimated probability</em>. One method is the <em>K-Nearest Neighbors</em> (KNN) approach.</p>
<p>The KNN classifier first identifies the <span class="math inline">\(K\)</span> points closest to <span class="math inline">\(x_0\)</span>, represented by <span class="math inline">\(N_0\)</span>. It then estimates the probability for class <span class="math inline">\(j\)</span> as a fraction of the observations in <span class="math inline">\(N_0\)</span> whose response is equal to <span class="math inline">\(j\)</span>.</p>
<p><span class="math display">\[
Pr(Y=j|X=x_{0}) = \frac{1}{k} \sum_{i \in N_{0}} I (y_{i}=j)
\]</span>
The KNN method then applies the Bayes rule and classifies <span class="math inline">\(x_0\)</span> to the class with the highest probability.</p>
<p>The choice of <span class="math inline">\(K\)</span> can have a drastic effect on the classification outcomes. Choosing a <span class="math inline">\(K\)</span> that is too low will yield a too-flexible model, with high variance and low bias. Conversely, a <span class="math inline">\(K\)</span> that is too high will result in a rigid classifier, with lower variance but higher bias.</p>
</div>
</div>
</div>
<div id="lab-introduction-to-r" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> 2.3 Lab: Introduction to R</h2>
<div id="basic-commands" class="section level3" number="1.3.1">
<h3><span class="header-section-number">1.3.1</span> 2.3.1 Basic Commands</h3>
<p>To run a function called <code>function</code>, we type <code>function(input)</code>. Objects are defined and then can be called by themselves.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create a vector of numbers with the c() function</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">5</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>x</span></code></pre></div>
<pre><code>## [1] 1 3 2 5</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(x)</span></code></pre></div>
<pre><code>## [1] 1 3 2 5</code></pre>
<p>We can check the length of an object in R using the <code>length()</code> function.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(x) <span class="co"># 4</span></span></code></pre></div>
<pre><code>## [1] 4</code></pre>
<p>The <code>matrix()</code> function can be used to create matrices of any size.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="at">data=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),<span class="at">nrow=</span><span class="dv">2</span>,<span class="at">ncol=</span><span class="dv">2</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>x</span></code></pre></div>
<pre><code>##      [,1] [,2]
## [1,]    1    3
## [2,]    2    4</code></pre>
<p>The <code>sqrt()</code> function returns the square root of an object passed to it.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(x) <span class="co"># 4</span></span></code></pre></div>
<pre><code>##          [,1]     [,2]
## [1,] 1.000000 1.732051
## [2,] 1.414214 2.000000</code></pre>
<p>The <code>rnorm()</code> function generates a vectors of random normal variables. We can use the <code>cor()</code> function to compute the correlation between two vectors.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">50</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> x <span class="sc">*</span> <span class="fu">rnorm</span>(<span class="dv">5</span>, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> .<span class="dv">1</span>)</span></code></pre></div>
</div>
<div id="graphics" class="section level3" number="1.3.2">
<h3><span class="header-section-number">1.3.2</span> 2.3.2 Graphics</h3>
<p><code>plot()</code> is the primary plotting function in base R. <code>plot(x,y)</code> will produce a plot with the vector <code>x</code> on the x-axis, and <code>y</code> on the y-axis.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, y)</span></code></pre></div>
<p><img src="pdf_document_files/figure-html/unnamed-chunk-12-1.png" width="672" />
Other useful functions:</p>
<ul>
<li><code>mean()</code></li>
<li><code>var()</code></li>
<li><code>sqrt()</code></li>
<li><code>sd()</code></li>
<li><code>pdf()</code></li>
<li><code>jpeg()</code></li>
<li><code>dev.off()</code></li>
<li><code>seq()</code></li>
</ul>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> x</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">outer</span>(x, y, <span class="cf">function</span>(x, y) <span class="fu">cos</span>(y) <span class="sc">/</span> (<span class="dv">1</span><span class="sc">+</span>x<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="fu">contour</span>(x, y, f)</span></code></pre></div>
<p><img src="pdf_document_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># contour(x, y, f, nlevels = 45, add = T)</span></span></code></pre></div>
</div>
<div id="indexing-data" class="section level3" number="1.3.3">
<h3><span class="header-section-number">1.3.3</span> 2.3.3 Indexing Data</h3>
<p>Indexing is useful for inspecting specific parts of whatever data we are working with.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>A <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">16</span>,<span class="dv">4</span>,<span class="dv">4</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>A</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4]
## [1,]    1    5    9   13
## [2,]    2    6   10   14
## [3,]    3    7   11   15
## [4,]    4    8   12   16</code></pre>
<p>To access the third element of the second column:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>A[<span class="dv">2</span>, <span class="dv">3</span>] <span class="co"># Row 2, Column 3</span></span></code></pre></div>
<pre><code>## [1] 10</code></pre>
<p>We can also access multiple rows or columns of data at once:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>A[<span class="fu">c</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">4</span>), <span class="dv">3</span>] <span class="co"># Rows 2 through 4, in Column 3</span></span></code></pre></div>
<pre><code>## [1] 10 11 12</code></pre>
</div>
<div id="loading-data" class="section level3" number="1.3.4">
<h3><span class="header-section-number">1.3.4</span> 2.3.4 Loading Data</h3>
<p>To work with data in R, the first step is to load it into your session. The <code>read.table()</code> function can be used for this. There are lots of other functions you can use to read data into your session, including those from external packages.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>Auto <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;data/Auto.data&quot;</span>)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Auto)</span></code></pre></div>
<pre><code>##     V1        V2           V3         V4     V5           V6   V7     V8                        V9
## 1  mpg cylinders displacement horsepower weight acceleration year origin                      name
## 2 18.0         8        307.0      130.0  3504.         12.0   70      1 chevrolet chevelle malibu
## 3 15.0         8        350.0      165.0  3693.         11.5   70      1         buick skylark 320
## 4 18.0         8        318.0      150.0  3436.         11.0   70      1        plymouth satellite
## 5 16.0         8        304.0      150.0  3433.         12.0   70      1             amc rebel sst
## 6 17.0         8        302.0      140.0  3449.         10.5   70      1               ford torino</code></pre>
<div id="troubleshooting" class="section level4" number="1.3.4.1">
<h4><span class="header-section-number">1.3.4.1</span> Troubleshooting</h4>
<p>It is a good idea to visually inspect your data before and after loading it into your R session. In this case, we have loaded the <code>Auto.data</code> incorrectly, and R assumes there are no column name values. To fix this:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>Auto <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;data/Auto.data&quot;</span>, </span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>                   <span class="co"># argument for a header</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>                   <span class="at">header =</span> T, </span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>                   <span class="co"># convert &quot;?&quot; strings to NA</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>                   <span class="at">na.strings =</span> <span class="st">&quot;?&quot;</span>)</span></code></pre></div>
<p>Other useful functions:<br />
- <code>na.omit()</code>
- <code>dim()</code></p>
</div>
</div>
<div id="additional-graphical-and-numerical-summaries" class="section level3" number="1.3.5">
<h3><span class="header-section-number">1.3.5</span> 2.3.5 Additional Graphical and Numerical Summaries</h3>
<p>We can use the <code>plot()</code> function to create <em>scatterplots</em> of quantitative variables. When using this function, it is necessary to specify the dataset name:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> <span class="fu">as.factor</span>(Auto<span class="sc">$</span>cylinders), <span class="at">y =</span> Auto<span class="sc">$</span>mpg)</span></code></pre></div>
<p><img src="pdf_document_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>In the graph above, <code>cylinder</code> is converted in a factor variable, since there are only a specific number of possible values. If the variable on the <span class="math inline">\(x\)</span>-axis is categorical, <em>boxplots</em> will automatically be drawn on the plot.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># There are many plot options available </span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(Auto<span class="sc">$</span>mpg, <span class="at">col =</span> <span class="st">&quot;purple&quot;</span>, </span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">breaks =</span> <span class="dv">15</span>, </span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Histogram of Miles per Gallon&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;MPG&quot;</span>)</span></code></pre></div>
<p><img src="pdf_document_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
</div>
</div>
<div id="exercises" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> 2.4 Exercises</h2>
<div id="conceptual" class="section level3" number="1.4.1">
<h3><span class="header-section-number">1.4.1</span> Conceptual</h3>
<div id="section" class="section level4" number="1.4.1.1">
<h4><span class="header-section-number">1.4.1.1</span> 1.</h4>
<p>For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.<br />
(a) The sample size <span class="math inline">\(n\)</span> is extremely large, and the number of predictors <span class="math inline">\(p\)</span> is small.<br />
&gt; A flexible model would benefit from the large sample and would fit the data better.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li><p>The number of predictors <span class="math inline">\(p\)</span> is extremely large, and the number of observations <span class="math inline">\(n\)</span> is small.<br />
&gt; A flexible model would perform worse here and overfit because of the small <span class="math inline">\(n\)</span>.</p></li>
<li><p>The relationship between the predictors and response is highly non-linear.<br />
&gt; In this case, a more flexible model would perform better than an inflexible one.</p></li>
<li><p>The variance of the error terms, i.e. <span class="math inline">\(\sigma^2 = Var(\epsilon)\)</span>, is extremely high.
&gt; A flexible method would do worse in this situation, because it would fit to the noise in the error terms.</p></li>
</ol>
</div>
<div id="section-1" class="section level4" number="1.4.1.2">
<h4><span class="header-section-number">1.4.1.2</span> 2.</h4>
<p>Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.<br />
&gt; Regression. <span class="math inline">\(n = 500\)</span>, <span class="math inline">\(p = 3\)</span> – profit, employees, and industry.</p></li>
<li><p>We are considering launching a new product and wish to know whether it will be a success or a failure. We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.<br />
&gt; Classification, the outcome variable will be either be ‘success’ or a ‘failure’. <span class="math inline">\(n = 20\)</span>, <span class="math inline">\(p = 13\)</span> – price, marketing budget, competition price, and the 10 other variables.</p></li>
</ol>
</div>
<div id="section-2" class="section level4" number="1.4.1.3">
<h4><span class="header-section-number">1.4.1.3</span> 3.</h4>
<p>We now revisit the bias-variance decomposition.</p>
<ol style="list-style-type: lower-alpha">
<li>Provide a sketch of typical (squared) bias, variance, training error, test error, and Bayes (or irreducible) error curves, on a single plot, as we go from less flexible statistical learning methods towards more flexible approaches. The x-axis should represent the amount of flexibility in the method, and the y-axis should represent the values for each curve. There should be five curves. Make sure to label each one.</li>
</ol>
<blockquote>
<p>An exercise left to the reader.</p>
</blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>Explain why each of the five curves has the shape displayed in part (a).</li>
</ol>
<blockquote>
<p>The squared bias decreases monotonically as model flexibility increases.
The variance increases monotonically as model flexibility increases.
The training MSE declines as model flexibility increases.
The test MSE initially declines, but begins to increase again as it starts to overfit.
The irreducible error is constant at a level &gt; 0.</p>
</blockquote>
</div>
<div id="section-3" class="section level4" number="1.4.1.4">
<h4><span class="header-section-number">1.4.1.4</span> 4.</h4>
<p>You will now think of some real-life applications for statistical learning.</p>
<ol style="list-style-type: lower-alpha">
<li>Describe three real-life applications in which classification might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.</li>
</ol>
<ul>
<li>Mortgage Loan application approvals. Response: Loan Approval/Denial. Predictors: Credit score, income, location.</li>
<li>Disease detection. Response: Disease classification. Predictors: Health, genetic markers, sex.</li>
<li>Product success. Response: Whether a product is successful or not. Predictors: Competitor price, market share.</li>
</ul>
<ol start="2" style="list-style-type: lower-alpha">
<li>Describe three real-life applications in which regression might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.</li>
</ol>
<blockquote>
<p>Discuss!</p>
</blockquote>
<ol start="3" style="list-style-type: lower-alpha">
<li>Describe three real-life applications in which cluster analysis might be useful.</li>
</ol>
<blockquote>
<p>Discuss!</p>
</blockquote>
</div>
<div id="section-4" class="section level4" number="1.4.1.5">
<h4><span class="header-section-number">1.4.1.5</span> 5.</h4>
<p>What are the advantages and disadvantages of a very flexible (versus a less flexible) approach for regression or classification? Under what circumstances might a more flexible approach be preferred to a less flexible approach? When might a less flexible approach be preferred?</p>
</div>
<div id="section-5" class="section level4" number="1.4.1.6">
<h4><span class="header-section-number">1.4.1.6</span> 6.</h4>
<p>Describe the differences between a parametric and a non-parametric statistical learning approach. What are the advantages of a parametric approach to regression or classification (as opposed to a non-parametric approach)? What are its disadvantages?</p>
</div>
<div id="section-6" class="section level4" number="1.4.1.7">
<h4><span class="header-section-number">1.4.1.7</span> 7.</h4>
<p>The table below provides a training data set containing six observations, three predictors, and one qualitative response variable.</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(Obs\)</span></th>
<th><span class="math inline">\(X_1\)</span></th>
<th><span class="math inline">\(X_2\)</span></th>
<th><span class="math inline">\(X_3\)</span></th>
<th><span class="math inline">\(Y\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(1\)</span></td>
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(3\)</span></td>
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(Red\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(2\)</span></td>
<td><span class="math inline">\(2\)</span></td>
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(Red\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(3\)</span></td>
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(1\)</span></td>
<td><span class="math inline">\(3\)</span></td>
<td><span class="math inline">\(Red\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(4\)</span></td>
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(1\)</span></td>
<td><span class="math inline">\(2\)</span></td>
<td><span class="math inline">\(Green\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(5\)</span></td>
<td><span class="math inline">\(-1\)</span></td>
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(1\)</span></td>
<td><span class="math inline">\(Green\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(6\)</span></td>
<td><span class="math inline">\(1\)</span></td>
<td><span class="math inline">\(1\)</span></td>
<td><span class="math inline">\(1\)</span></td>
<td><span class="math inline">\(Red\)</span></td>
</tr>
</tbody>
</table>
<p>Suppose we wish to use this data set to make a prediction for Y when <span class="math inline">\(X_1 = X_2 = X_3 = 0\)</span> using <span class="math inline">\(K\)</span>-nearest neighbors.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Compute the Euclidean distance between each observation and the test point, <span class="math inline">\(X_1 = X_2 = X_3 = 0\)</span>.</p></li>
<li><p>What is our prediction with <span class="math inline">\(K = 1\)</span>? Why?<br />
</p></li>
<li><p>What is our prediction with <span class="math inline">\(K = 3\)</span>? Why?<br />
</p></li>
<li><p>If the Bayes decision boundary in this problem is highly non-linear, then would we expect the best value for <span class="math inline">\(K\)</span> to be large or small? Why?</p></li>
</ol>
</div>
</div>
<div id="applied" class="section level3" number="1.4.2">
<h3><span class="header-section-number">1.4.2</span> Applied</h3>
<div id="section-7" class="section level4" number="1.4.2.1">
<h4><span class="header-section-number">1.4.2.1</span> 8.</h4>
<p>This exercise relates to the <code>College</code> data set, which can be found in the file College.csv. It contains a number of variables for 777 different universities and colleges in the US. The variables are</p>
<ul>
<li><code>Private</code>: Public/private indicator</li>
<li><code>Apps</code>: Number of applications received</li>
<li><code>Accept</code>: Number of applicants accepted</li>
<li><code>Enroll</code>: Number of new students enrolled</li>
<li><code>Top10perc</code>: New students from top 10% of high school class</li>
<li><code>Top25perc</code>: New students from top 25% of high school class</li>
<li><code>F.Undergrad</code>: Number of full-time undergraduates</li>
<li><code>P.Undergrad</code>: Number of part-time undergraduates</li>
<li><code>Outstate</code>: Out-of-state tuition</li>
<li><code>Room.Board</code>: Room and board costs</li>
<li><code>Books</code>: Estimated book costs</li>
<li><code>Personal</code>: Estimated personal spending</li>
<li><code>PhD</code>:Percent of faculty with Ph.D.’s</li>
<li><code>Terminal</code>:Percent of faculty with terminal degree</li>
<li><code>S.F.Ratio</code>: Student/faculty ratio</li>
<li><code>perc.alumni</code>: Percent of alumni who donate</li>
<li><code>Expend</code>: Instructional expenditure per student</li>
<li><code>Grad.Rate</code>: Graduation rate</li>
</ul>
<p>Before reading the data into R, it can be viewed in Excel or a text editor.</p>
<ol style="list-style-type: lower-alpha">
<li>Use the <code>read.csv()</code> function to read the data into R. Call the loaded data <code>college</code>. Make sure that you have the directory set to the correct location for the data.</li>
</ol>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">file.exists</span>(<span class="st">&quot;data/Collage.csv&quot;</span>)){</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">download.file</span>(<span class="st">&quot;https://www.statlearning.com/s/College.csv&quot;</span>, <span class="at">destfile =</span> <span class="st">&quot;data/College.csv&quot;</span>)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>college <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;data/College.csv&quot;</span>)</span></code></pre></div>
<ol start="2" style="list-style-type: lower-alpha">
<li>Look at the data using the fix() function. You should notice that the first column is just the name of each university. We don’t really want R to treat this as data. However, it may be handy to have these names for later. Try the following commands:</li>
</ol>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fix(college)</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="co"># add first column as rownames</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(college) <span class="ot">&lt;-</span> college[, <span class="dv">1</span>]</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>college <span class="ot">&lt;-</span> college[, <span class="sc">-</span><span class="dv">1</span>]</span></code></pre></div>
<ol start="3" style="list-style-type: lower-alpha">
<li><ol style="list-style-type: lower-roman">
<li>Use the <code>summary()</code> function to produce a numerical summary of the variables in the data set.</li>
</ol></li>
</ol>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(college)</span></code></pre></div>
<pre><code>##  Private        Apps           Accept          Enroll       Top10perc       Top25perc      F.Undergrad     P.Undergrad         Outstate    
##  No :212   Min.   :   81   Min.   :   72   Min.   :  35   Min.   : 1.00   Min.   :  9.0   Min.   :  139   Min.   :    1.0   Min.   : 2340  
##  Yes:565   1st Qu.:  776   1st Qu.:  604   1st Qu.: 242   1st Qu.:15.00   1st Qu.: 41.0   1st Qu.:  992   1st Qu.:   95.0   1st Qu.: 7320  
##            Median : 1558   Median : 1110   Median : 434   Median :23.00   Median : 54.0   Median : 1707   Median :  353.0   Median : 9990  
##            Mean   : 3002   Mean   : 2019   Mean   : 780   Mean   :27.56   Mean   : 55.8   Mean   : 3700   Mean   :  855.3   Mean   :10441  
##            3rd Qu.: 3624   3rd Qu.: 2424   3rd Qu.: 902   3rd Qu.:35.00   3rd Qu.: 69.0   3rd Qu.: 4005   3rd Qu.:  967.0   3rd Qu.:12925  
##            Max.   :48094   Max.   :26330   Max.   :6392   Max.   :96.00   Max.   :100.0   Max.   :31643   Max.   :21836.0   Max.   :21700  
##    Room.Board       Books           Personal         PhD            Terminal       S.F.Ratio      perc.alumni        Expend     
##  Min.   :1780   Min.   :  96.0   Min.   : 250   Min.   :  8.00   Min.   : 24.0   Min.   : 2.50   Min.   : 0.00   Min.   : 3186  
##  1st Qu.:3597   1st Qu.: 470.0   1st Qu.: 850   1st Qu.: 62.00   1st Qu.: 71.0   1st Qu.:11.50   1st Qu.:13.00   1st Qu.: 6751  
##  Median :4200   Median : 500.0   Median :1200   Median : 75.00   Median : 82.0   Median :13.60   Median :21.00   Median : 8377  
##  Mean   :4358   Mean   : 549.4   Mean   :1341   Mean   : 72.66   Mean   : 79.7   Mean   :14.09   Mean   :22.74   Mean   : 9660  
##  3rd Qu.:5050   3rd Qu.: 600.0   3rd Qu.:1700   3rd Qu.: 85.00   3rd Qu.: 92.0   3rd Qu.:16.50   3rd Qu.:31.00   3rd Qu.:10830  
##  Max.   :8124   Max.   :2340.0   Max.   :6800   Max.   :103.00   Max.   :100.0   Max.   :39.80   Max.   :64.00   Max.   :56233  
##    Grad.Rate     
##  Min.   : 10.00  
##  1st Qu.: 53.00  
##  Median : 65.00  
##  Mean   : 65.46  
##  3rd Qu.: 78.00  
##  Max.   :118.00</code></pre>
<ol start="3" style="list-style-type: lower-alpha">
<li><ol start="2" style="list-style-type: lower-roman">
<li>Use the <code>pairs()</code> function to produce a scatterplot matrix of the first ten columns or variables of the data. Recall that you can reference the first ten columns of a matrix <code>A</code> using <code>A[,1:10]</code>.</li>
</ol></li>
</ol>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(college[, <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>])</span></code></pre></div>
<p><img src="pdf_document_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<ol start="3" style="list-style-type: lower-alpha">
<li><ol start="3" style="list-style-type: lower-roman">
<li>Use the <code>plot()</code> function to produce side-by-side boxplots of <code>Outstate</code> versus <code>Private</code>.</li>
</ol></li>
</ol>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">as.factor</span>(college<span class="sc">$</span>Private), college<span class="sc">$</span>Outstate, <span class="at">xlab =</span> <span class="st">&quot;Private&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Out-of-state Tuition&quot;</span>)</span></code></pre></div>
<p><img src="pdf_document_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<ol start="3" style="list-style-type: lower-alpha">
<li><ol start="22" style="list-style-type: lower-alpha">
<li>Create a new qualitative variable, called <code>Elite</code>, by binning the <code>Top10perc</code> variable. We are going to divide universitiesinto two groups based on whether or not the proportion of students coming from the top 10% of their high school classes exceeds 50%.</li>
</ol></li>
</ol>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>Elite <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="st">&quot;No&quot;</span>,<span class="fu">nrow</span>(college))</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>Elite[college<span class="sc">$</span>Top10perc<span class="sc">&gt;</span><span class="dv">50</span>]<span class="ot">=</span><span class="st">&quot;Yes&quot;</span> </span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>Elite <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(Elite)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>college<span class="ot">=</span><span class="fu">data.frame</span>(college,Elite)</span></code></pre></div>
<p>Use the <code>summary()</code> function to see how many elite universities there are. Now use the <code>plot()</code> function to produce side-by-side boxplots of <code>Outstate</code> versus <code>Elite</code>.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(college<span class="sc">$</span>Elite)</span></code></pre></div>
<pre><code>##  No Yes 
## 699  78</code></pre>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">as.factor</span>(college<span class="sc">$</span>Elite), college<span class="sc">$</span>Outstate, <span class="at">xlab =</span> <span class="st">&quot;Elite&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Out-of-state Tuition&quot;</span>)</span></code></pre></div>
<p><img src="pdf_document_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<ol start="3" style="list-style-type: lower-alpha">
<li><ol start="22" style="list-style-type: lower-alpha">
<li>Use the <code>hist()</code> function to produce some histograms with differing numbers of bins for a few of the quantitative variables. You may find the command <code>par(mfrow=c(2,2))</code> useful: it will divide the print window into four regions so that four plots can be made simultaneously. Modifying the arguments to this function will divide the screen in other ways.</li>
</ol></li>
</ol>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(college<span class="sc">$</span>Top10perc)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(college<span class="sc">$</span>F.Undergrad, <span class="at">breaks =</span> <span class="dv">15</span>)</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(college<span class="sc">$</span>S.F.Ratio, <span class="at">breaks =</span> <span class="dv">5</span>)</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(college<span class="sc">$</span>Room.Board, <span class="at">breaks =</span> <span class="dv">10</span>)</span></code></pre></div>
<p><img src="pdf_document_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<ol start="3" style="list-style-type: lower-alpha">
<li><ol start="6" style="list-style-type: lower-roman">
<li>Continue exploring the data, and provide a brief summary of what you discover.</li>
</ol></li>
</ol>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(college<span class="sc">$</span>S.F.Ratio, college<span class="sc">$</span>perc.alumni,</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Student/Faculty Ratio&quot;</span>, </span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Percent of Alumni who Donate&quot;</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>     )</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">predict</span>(<span class="fu">lm</span>(perc.alumni<span class="sc">~</span>S.F.Ratio, <span class="at">data =</span> college)),</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">col=</span><span class="st">&#39;red&#39;</span>)</span></code></pre></div>
<p><img src="pdf_document_files/figure-html/unnamed-chunk-29-1.png" width="672" />
&gt; Plotting Student/Faculty ratio and the percent of alumni who donate does not show clear relationship that I thought would show up. etc etc discuss.</p>
</div>
<div id="section-8" class="section level4" number="1.4.2.2">
<h4><span class="header-section-number">1.4.2.2</span> 9.</h4>
<p>This exercise involves the <code>Auto</code> data set studied in the lab. Make sure that the missing values have been removed from the data.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>Auto <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;data/Auto.data&quot;</span>, <span class="at">header =</span> T, <span class="at">na.strings =</span> <span class="st">&quot;?&quot;</span>)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>Auto <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(Auto)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(Auto)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    392 obs. of  9 variables:
##  $ mpg         : num  18 15 18 16 17 15 14 14 14 15 ...
##  $ cylinders   : int  8 8 8 8 8 8 8 8 8 8 ...
##  $ displacement: num  307 350 318 304 302 429 454 440 455 390 ...
##  $ horsepower  : num  130 165 150 150 140 198 220 215 225 190 ...
##  $ weight      : num  3504 3693 3436 3433 3449 ...
##  $ acceleration: num  12 11.5 11 12 10.5 10 9 8.5 10 8.5 ...
##  $ year        : int  70 70 70 70 70 70 70 70 70 70 ...
##  $ origin      : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ name        : Factor w/ 304 levels &quot;amc ambassador brougham&quot;,..: 49 36 231 14 161 141 54 223 241 2 ...
##  - attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int  33 127 331 337 355
##   ..- attr(*, &quot;names&quot;)= chr  &quot;33&quot; &quot;127&quot; &quot;331&quot; &quot;337&quot; ...</code></pre>
<ol style="list-style-type: lower-alpha">
<li>Which of the predictors are quantitative, and which are qualitative?</li>
</ol>
<p>Cylinders, origin, and name are the qualitative variables. The rest of the variables are quantitative.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>What is the range of each quantitative predictor? You can answer this using the range() function.</li>
</ol>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># this is a fancy way to do this</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>vars <span class="ot">&lt;-</span> <span class="fu">setdiff</span>(<span class="fu">names</span>(Auto), <span class="fu">c</span>(<span class="st">&quot;cylinders&quot;</span>, <span class="st">&quot;origin&quot;</span>, <span class="st">&quot;name&quot;</span>))</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sapply</span>(vars, <span class="cf">function</span>(v) <span class="fu">range</span>(Auto[v]), <span class="at">USE.NAMES =</span> T)</span></code></pre></div>
<pre><code>##       mpg displacement horsepower weight acceleration year
## [1,]  9.0           68         46   1613          8.0   70
## [2,] 46.6          455        230   5140         24.8   82</code></pre>
<ol start="3" style="list-style-type: lower-alpha">
<li>What is the mean and standard deviation of each quantitative predictor?</li>
</ol>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sapply</span>(Auto[, vars], mean, <span class="at">USE.NAMES =</span> T)</span></code></pre></div>
<pre><code>##          mpg displacement   horsepower       weight acceleration         year 
##     23.44592    194.41199    104.46939   2977.58418     15.54133     75.97959</code></pre>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sapply</span>(Auto[, vars], sd, <span class="at">USE.NAMES =</span> T)</span></code></pre></div>
<pre><code>##          mpg displacement   horsepower       weight acceleration         year 
##     7.805007   104.644004    38.491160   849.402560     2.758864     3.683737</code></pre>
<ol start="4" style="list-style-type: lower-alpha">
<li>Now remove the 10th through 85th observations. What is the range, mean, and standard deviation of each predictor in the
subset of the data that remains?</li>
</ol>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>new_auto <span class="ot">&lt;-</span> Auto[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">10</span><span class="sc">:</span><span class="dv">85</span>)]</span></code></pre></div>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sapply</span>(new_auto[, vars], range, <span class="at">USE.NAMES =</span> T)</span></code></pre></div>
<pre><code>##       mpg displacement horsepower weight acceleration year
## [1,]  9.0           68         46   1613          8.0   70
## [2,] 46.6          455        230   5140         24.8   82</code></pre>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sapply</span>(new_auto[, vars], mean, <span class="at">USE.NAMES =</span> T)</span></code></pre></div>
<pre><code>##          mpg displacement   horsepower       weight acceleration         year 
##     23.44592    194.41199    104.46939   2977.58418     15.54133     75.97959</code></pre>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sapply</span>(new_auto[, vars], sd, <span class="at">USE.NAMES =</span> T)</span></code></pre></div>
<pre><code>##          mpg displacement   horsepower       weight acceleration         year 
##     7.805007   104.644004    38.491160   849.402560     2.758864     3.683737</code></pre>
<ol start="5" style="list-style-type: lower-alpha">
<li>Using the full data set, investigate the predictors graphically, using scatterplots or other tools of your choice. Create some plots highlighting the relationships among the predictors. Comment on your findings.</li>
</ol>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(Auto)</span></code></pre></div>
<p><img src="pdf_document_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Suppose that we wish to predict gas mileage ( mpg ) on the basis of the other variables. Do your plots suggest that any of the other variables might be useful in predicting mpg ? Justify your answer.</li>
</ol>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(Auto<span class="sc">$</span>weight, Auto<span class="sc">$</span>horsepower)</span></code></pre></div>
<pre><code>## [1] 0.8645377</code></pre>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(Auto<span class="sc">$</span>weight, Auto<span class="sc">$</span>displacement)</span></code></pre></div>
<pre><code>## [1] 0.9329944</code></pre>
</div>
<div id="section-9" class="section level4" number="1.4.2.3">
<h4><span class="header-section-number">1.4.2.3</span> 10.</h4>
<p>This exercise involves the Boston housing data set.</p>
<ol style="list-style-type: lower-alpha">
<li>To begin, load in the Boston data set. The Boston data set is part of the <code>MASS</code> library in R.</li>
</ol>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>Boston</span></code></pre></div>
<pre><code>##       crim    zn indus chas    nox    rm   age    dis rad tax ptratio  black lstat medv
## 1  0.00632  18.0  2.31    0 0.5380 6.575  65.2 4.0900   1 296    15.3 396.90  4.98 24.0
## 2  0.02731   0.0  7.07    0 0.4690 6.421  78.9 4.9671   2 242    17.8 396.90  9.14 21.6
## 3  0.02729   0.0  7.07    0 0.4690 7.185  61.1 4.9671   2 242    17.8 392.83  4.03 34.7
## 4  0.03237   0.0  2.18    0 0.4580 6.998  45.8 6.0622   3 222    18.7 394.63  2.94 33.4
## 5  0.06905   0.0  2.18    0 0.4580 7.147  54.2 6.0622   3 222    18.7 396.90  5.33 36.2
## 6  0.02985   0.0  2.18    0 0.4580 6.430  58.7 6.0622   3 222    18.7 394.12  5.21 28.7
## 7  0.08829  12.5  7.87    0 0.5240 6.012  66.6 5.5605   5 311    15.2 395.60 12.43 22.9
## 8  0.14455  12.5  7.87    0 0.5240 6.172  96.1 5.9505   5 311    15.2 396.90 19.15 27.1
## 9  0.21124  12.5  7.87    0 0.5240 5.631 100.0 6.0821   5 311    15.2 386.63 29.93 16.5
## 10 0.17004  12.5  7.87    0 0.5240 6.004  85.9 6.5921   5 311    15.2 386.71 17.10 18.9
## 11 0.22489  12.5  7.87    0 0.5240 6.377  94.3 6.3467   5 311    15.2 392.52 20.45 15.0
## 12 0.11747  12.5  7.87    0 0.5240 6.009  82.9 6.2267   5 311    15.2 396.90 13.27 18.9
## 13 0.09378  12.5  7.87    0 0.5240 5.889  39.0 5.4509   5 311    15.2 390.50 15.71 21.7
## 14 0.62976   0.0  8.14    0 0.5380 5.949  61.8 4.7075   4 307    21.0 396.90  8.26 20.4
## 15 0.63796   0.0  8.14    0 0.5380 6.096  84.5 4.4619   4 307    21.0 380.02 10.26 18.2
## 16 0.62739   0.0  8.14    0 0.5380 5.834  56.5 4.4986   4 307    21.0 395.62  8.47 19.9
## 17 1.05393   0.0  8.14    0 0.5380 5.935  29.3 4.4986   4 307    21.0 386.85  6.58 23.1
## 18 0.78420   0.0  8.14    0 0.5380 5.990  81.7 4.2579   4 307    21.0 386.75 14.67 17.5
## 19 0.80271   0.0  8.14    0 0.5380 5.456  36.6 3.7965   4 307    21.0 288.99 11.69 20.2
## 20 0.72580   0.0  8.14    0 0.5380 5.727  69.5 3.7965   4 307    21.0 390.95 11.28 18.2
## 21 1.25179   0.0  8.14    0 0.5380 5.570  98.1 3.7979   4 307    21.0 376.57 21.02 13.6
## 22 0.85204   0.0  8.14    0 0.5380 5.965  89.2 4.0123   4 307    21.0 392.53 13.83 19.6
## 23 1.23247   0.0  8.14    0 0.5380 6.142  91.7 3.9769   4 307    21.0 396.90 18.72 15.2
## 24 0.98843   0.0  8.14    0 0.5380 5.813 100.0 4.0952   4 307    21.0 394.54 19.88 14.5
## 25 0.75026   0.0  8.14    0 0.5380 5.924  94.1 4.3996   4 307    21.0 394.33 16.30 15.6
## 26 0.84054   0.0  8.14    0 0.5380 5.599  85.7 4.4546   4 307    21.0 303.42 16.51 13.9
## 27 0.67191   0.0  8.14    0 0.5380 5.813  90.3 4.6820   4 307    21.0 376.88 14.81 16.6
## 28 0.95577   0.0  8.14    0 0.5380 6.047  88.8 4.4534   4 307    21.0 306.38 17.28 14.8
## 29 0.77299   0.0  8.14    0 0.5380 6.495  94.4 4.4547   4 307    21.0 387.94 12.80 18.4
## 30 1.00245   0.0  8.14    0 0.5380 6.674  87.3 4.2390   4 307    21.0 380.23 11.98 21.0
## 31 1.13081   0.0  8.14    0 0.5380 5.713  94.1 4.2330   4 307    21.0 360.17 22.60 12.7
## 32 1.35472   0.0  8.14    0 0.5380 6.072 100.0 4.1750   4 307    21.0 376.73 13.04 14.5
## 33 1.38799   0.0  8.14    0 0.5380 5.950  82.0 3.9900   4 307    21.0 232.60 27.71 13.2
## 34 1.15172   0.0  8.14    0 0.5380 5.701  95.0 3.7872   4 307    21.0 358.77 18.35 13.1
## 35 1.61282   0.0  8.14    0 0.5380 6.096  96.9 3.7598   4 307    21.0 248.31 20.34 13.5
## 36 0.06417   0.0  5.96    0 0.4990 5.933  68.2 3.3603   5 279    19.2 396.90  9.68 18.9
## 37 0.09744   0.0  5.96    0 0.4990 5.841  61.4 3.3779   5 279    19.2 377.56 11.41 20.0
## 38 0.08014   0.0  5.96    0 0.4990 5.850  41.5 3.9342   5 279    19.2 396.90  8.77 21.0
## 39 0.17505   0.0  5.96    0 0.4990 5.966  30.2 3.8473   5 279    19.2 393.43 10.13 24.7
## 40 0.02763  75.0  2.95    0 0.4280 6.595  21.8 5.4011   3 252    18.3 395.63  4.32 30.8
## 41 0.03359  75.0  2.95    0 0.4280 7.024  15.8 5.4011   3 252    18.3 395.62  1.98 34.9
## 42 0.12744   0.0  6.91    0 0.4480 6.770   2.9 5.7209   3 233    17.9 385.41  4.84 26.6
## 43 0.14150   0.0  6.91    0 0.4480 6.169   6.6 5.7209   3 233    17.9 383.37  5.81 25.3
## 44 0.15936   0.0  6.91    0 0.4480 6.211   6.5 5.7209   3 233    17.9 394.46  7.44 24.7
## 45 0.12269   0.0  6.91    0 0.4480 6.069  40.0 5.7209   3 233    17.9 389.39  9.55 21.2
## 46 0.17142   0.0  6.91    0 0.4480 5.682  33.8 5.1004   3 233    17.9 396.90 10.21 19.3
## 47 0.18836   0.0  6.91    0 0.4480 5.786  33.3 5.1004   3 233    17.9 396.90 14.15 20.0
## 48 0.22927   0.0  6.91    0 0.4480 6.030  85.5 5.6894   3 233    17.9 392.74 18.80 16.6
## 49 0.25387   0.0  6.91    0 0.4480 5.399  95.3 5.8700   3 233    17.9 396.90 30.81 14.4
## 50 0.21977   0.0  6.91    0 0.4480 5.602  62.0 6.0877   3 233    17.9 396.90 16.20 19.4
## 51 0.08873  21.0  5.64    0 0.4390 5.963  45.7 6.8147   4 243    16.8 395.56 13.45 19.7
## 52 0.04337  21.0  5.64    0 0.4390 6.115  63.0 6.8147   4 243    16.8 393.97  9.43 20.5
## 53 0.05360  21.0  5.64    0 0.4390 6.511  21.1 6.8147   4 243    16.8 396.90  5.28 25.0
## 54 0.04981  21.0  5.64    0 0.4390 5.998  21.4 6.8147   4 243    16.8 396.90  8.43 23.4
## 55 0.01360  75.0  4.00    0 0.4100 5.888  47.6 7.3197   3 469    21.1 396.90 14.80 18.9
## 56 0.01311  90.0  1.22    0 0.4030 7.249  21.9 8.6966   5 226    17.9 395.93  4.81 35.4
## 57 0.02055  85.0  0.74    0 0.4100 6.383  35.7 9.1876   2 313    17.3 396.90  5.77 24.7
## 58 0.01432 100.0  1.32    0 0.4110 6.816  40.5 8.3248   5 256    15.1 392.90  3.95 31.6
## 59 0.15445  25.0  5.13    0 0.4530 6.145  29.2 7.8148   8 284    19.7 390.68  6.86 23.3
## 60 0.10328  25.0  5.13    0 0.4530 5.927  47.2 6.9320   8 284    19.7 396.90  9.22 19.6
## 61 0.14932  25.0  5.13    0 0.4530 5.741  66.2 7.2254   8 284    19.7 395.11 13.15 18.7
## 62 0.17171  25.0  5.13    0 0.4530 5.966  93.4 6.8185   8 284    19.7 378.08 14.44 16.0
## 63 0.11027  25.0  5.13    0 0.4530 6.456  67.8 7.2255   8 284    19.7 396.90  6.73 22.2
## 64 0.12650  25.0  5.13    0 0.4530 6.762  43.4 7.9809   8 284    19.7 395.58  9.50 25.0
## 65 0.01951  17.5  1.38    0 0.4161 7.104  59.5 9.2229   3 216    18.6 393.24  8.05 33.0
## 66 0.03584  80.0  3.37    0 0.3980 6.290  17.8 6.6115   4 337    16.1 396.90  4.67 23.5
## 67 0.04379  80.0  3.37    0 0.3980 5.787  31.1 6.6115   4 337    16.1 396.90 10.24 19.4
## 68 0.05789  12.5  6.07    0 0.4090 5.878  21.4 6.4980   4 345    18.9 396.21  8.10 22.0
## 69 0.13554  12.5  6.07    0 0.4090 5.594  36.8 6.4980   4 345    18.9 396.90 13.09 17.4
## 70 0.12816  12.5  6.07    0 0.4090 5.885  33.0 6.4980   4 345    18.9 396.90  8.79 20.9
## 71 0.08826   0.0 10.81    0 0.4130 6.417   6.6 5.2873   4 305    19.2 383.73  6.72 24.2
##  [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 435 rows ]</code></pre>
<p>Now the data set is contained in the object Boston. Read about the data set:</p>
<pre><code>?Boston</code></pre>
<p>How many rows are in this data set? How many columns? What do the rows and columns represent?</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(Boston) <span class="co"># 506 </span></span></code></pre></div>
<pre><code>## [1] 506</code></pre>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(Boston) <span class="co"># 14 columns </span></span></code></pre></div>
<pre><code>## [1] 14</code></pre>
<blockquote>
<p>The rows represent suburbs of Boston, and each column is a different variable.</p>
</blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>Make some pairwise scatterplots of the predictors (columns) in this data set. Describe your findings.</li>
</ol>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(Boston<span class="sc">$</span>nox, Boston<span class="sc">$</span>medv)</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(Boston<span class="sc">$</span>rm, Boston<span class="sc">$</span>indus)</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(Boston<span class="sc">$</span>age, Boston<span class="sc">$</span>black)</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(Boston<span class="sc">$</span>dis, Boston<span class="sc">$</span>crim)</span></code></pre></div>
<p><img src="pdf_document_files/figure-html/unnamed-chunk-42-1.png" width="672" /></p>
<ol start="3" style="list-style-type: lower-alpha">
<li><p>Are any of the predictors associated with per capita crime rate? If so, explain the relationship.</p></li>
<li><p>Do any of the suburbs of Boston appear to have particularly high crime rates? Tax rates? Pupil-teacher ratios? Comment on the range of each predictor.</p></li>
</ol>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(Boston<span class="sc">$</span>crim)</span></code></pre></div>
<p><img src="pdf_document_files/figure-html/unnamed-chunk-44-1.png" width="672" /></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>How many of the suburbs in this data set bound the Charles river?</li>
</ol>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(Boston<span class="sc">$</span>chas)</span></code></pre></div>
<pre><code>## [1] 35</code></pre>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
